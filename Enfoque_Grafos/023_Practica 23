# TEMA: MDP — Modela decisiones con estados, acciones, transiciones y recompensas

# Mismo que Value Iteration, pero más explícito
estados = ['S1', 'S2']
acciones = {
    'S1': {'ir_S2': {'S2': 1.0}},
    'S2': {'quedarse': {'S2': 1.0}}
}
recompensas = {
    'S1': {'ir_S2': 0},
    'S2': {'quedarse': 10}
}
descuento = 0.9
V = {s: 0 for s in estados}

# Iteración de valores estilo MDP
for _ in range(5):
    for s in estados:
        valores_accion = []
        for a in acciones[s]:
            valor = sum(prob * (recompensas[s][a] + descuento * V[dest]) for dest, prob in acciones[s][a].items())
            valores_accion.append(valor)
        V[s] = max(valores_accion)

print("Valores MDP por estado:", V)
